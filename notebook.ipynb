import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

!pip install -q spacy scikit-learn
!python -m spacy download en_core_web_sm

import pandas as pd
import spacy
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
df = pd.read_csv("/kaggle/input/cleaned-indian-recipes-dataset/Cleaned_Indian_Food_Dataset.csv")
df.head(10)
df.tail()
df.columns
df.isnull().sum()
df['Cuisine'].unique()

nlp = spacy.load("en_core_web_sm")

def preprocess(text):
    text = str(text).lower()
    doc = nlp(text)
    return " ".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])
df = df.dropna(subset=["TranslatedIngredients", "TranslatedInstructions"])
df["clean_ingredients"] = df["TranslatedIngredients"].apply(preprocess)
vectorizer = TfidfVectorizer()
ingredient_vectors = vectorizer.fit_transform(df["clean_ingredients"])
def get_recipes(user_ingredients, top_n=5):
    cleaned_input = preprocess(user_ingredients)
    user_vector = vectorizer.transform([cleaned_input])
    similarity_scores = cosine_similarity(user_vector, ingredient_vectors).flatten()
    top_matches = similarity_scores.argsort()[-top_n:][::-1]
    return df.iloc[top_matches][[
        "TranslatedRecipeName", 
        "TranslatedIngredients", 
        "TranslatedInstructions", 
        "Cuisine"
    ]]

user_input = input("Enter available ingredients (comma separated): ")
results = get_recipes(user_input)
for i, row in results.iterrows():
    print("\n" + "-"*30)
    print(f" Recipe: {row['TranslatedRecipeName']}")
    print(f" Cuisine: {row['Cuisine']}")
    print(f" Ingredients: {row['TranslatedIngredients']}")
    print(f" Instructions: {row['TranslatedInstructions']}")
